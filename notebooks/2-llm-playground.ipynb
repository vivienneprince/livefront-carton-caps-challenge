{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab73bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "import os, sys\n",
    "import httpcore, httpx, requests, urllib3\n",
    "import logging, time\n",
    "\n",
    "\n",
    "main_dir = os.path.abspath('..')\n",
    "sys.path.append(main_dir)\n",
    "# os.chdir(main_dir)\n",
    "\n",
    "# logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s:%(name)s:%(filename)s - %(message)s',\n",
    "    handlers=[logging.FileHandler(\n",
    "        f'{main_dir}/logs/log_{time.strftime(\"%Y%m%d\")}.log'), logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "pkgs_warn_only = ['urllib3', 'requests', 'httpx', 'httpcore']\n",
    "[logging.getLogger(pkg).setLevel(logging.WARNING) for pkg in pkgs_warn_only]\n",
    "\n",
    "notebook_name = __vsc_ipynb_file__[__vsc_ipynb_file__.rfind('/')+1:]\n",
    "log = logging.getLogger(f'{notebook_name}_logger')\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f57b2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:45:46,804 - DEBUG:openai._base_client:_base_client.py - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a travel agent. Be descriptive and helpful.'}, {'role': 'user', 'content': 'Tell me the top 3 things to do in Colorado.'}], 'model': 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', 'max_tokens': 512, 'stream': False, 'temperature': 0.8, 'tools': None, 'top_p': 0.9}}\n",
      "2025-05-09 22:45:46,814 - DEBUG:openai._base_client:_base_client.py - Sending HTTP Request: POST https://api.together.xyz/v1/chat/completions\n",
      "2025-05-09 22:45:52,465 - DEBUG:openai._base_client:_base_client.py - HTTP Response: POST https://api.together.xyz/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 10 May 2025 04:45:52 GMT', 'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93d6ca002ee3e755-DEN', 'cf-cache-status': 'DYNAMIC', 'retry-after': '2', 'access-control-allow-origin': '*', 'etag': 'W/\"b68-UoDNj3aEPIIyn2zE66nWHEApG4o\"', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-amzn-trace-id': 'e8c11e36-c674-4fd5-b649-6515cb7ad94a-noamzn', 'x-api-call-end': '2025-05-10T04:45:52.476Z', 'x-api-call-start': '2025-05-10T04:45:47.146Z', 'x-api-received': '2025-05-10T04:45:47.137Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '10', 'x-ratelimit-limit-tokens': '3000', 'x-ratelimit-remaining': '19', 'x-ratelimit-remaining-tokens': '3000', 'x-ratelimit-reset': '2', 'x-request-id': 'ntSMtPA-zqrih-93d6ca002ee3e755', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-05-09 22:45:52,466 - DEBUG:openai._base_client:_base_client.py - request_id: ntSMtPA-zqrih-93d6ca002ee3e755\n",
      "2025-05-09 22:45:52,469 - DEBUG:utils.llms:llms.py - Generating response; prompt= [{'role': 'system', 'content': 'You are a travel agent. Be descriptive and helpful.'}, {'role': 'user', 'content': 'Tell me the top 3 things to do in Colorado.'}]\n",
      "2025-05-09 22:45:52,469 - DEBUG:utils.llms:llms.py - Returning result as string only: Colorado! The Centennial State is a paradise for outdoor enthusiasts, foodies, and adventure-seekers alike. With its breathtaking Rocky Mountains, charming towns, and vibrant cities, Colorado has something for everyone. Here are the top 3 things to do in Colorado:\n",
      "\n",
      "1. **Explore the Rocky Mountain National Park**: A must-visit destination in Colorado, Rocky Mountain National Park is a stunning showcase of alpine grandeur. With over 60 mountain peaks above 12,000 feet, including Longs Peak, the park offers endless opportunities for hiking, camping, and wildlife viewing. Take a scenic drive on the Trail Ridge Road, the highest paved road in the US, and marvel at the breathtaking vistas. Keep an eye out for elk, moose, and bighorn sheep roaming freely in their natural habitat.\n",
      "\n",
      "Some popular trails in the park include:\n",
      "\t* Bear Lake Trail: A moderate 3.5-mile loop around Bear Lake, offering stunning views of the surrounding mountains.\n",
      "\t* Alberta Falls Trail: A 3.8-mile out-and-back trail that takes you to a picturesque waterfall.\n",
      "\t* Longs Peak Trail: A challenging 14.5-mile out-and-back trail that rewards hikers with panoramic views from the summit.\n",
      "\n",
      "2. **Experience the Thrill of Skiing or Snowboarding in the Rockies**: Colorado is renowned for its world-class ski resorts, and for good reason. With some of the best snow on the planet, resorts like Vail, Aspen, and Breckenridge offer an unforgettable winter sports experience. Whether you're a seasoned pro or a beginner, you'll find a resort that suits your style. Enjoy the thrill of speeding down the slopes, take in the stunning mountain views, and cozy up by the fire with a warm cup of hot chocolate.\n",
      "\n",
      "Some top ski resorts in Colorado include:\n",
      "\t* Vail: With over 5,200 acres of skiable terrain, Vail is one of the largest ski resorts in the US.\n",
      "\t* Aspen: A luxurious ski destination with four separate ski areas: Aspen Mountain, Aspen Highlands, Buttermilk, and Snowmass.\n",
      "\t* Breckenridge: A lively ski resort with a wide range of terrain, from gentle groomers to challenging black diamond runs.\n",
      "\n",
      "3. **Discover the Charm of Downtown Aspen**: Aspen is a picturesque mountain town that's as famous for its natural beauty as it is for its cultural attractions. Stroll through the charming downtown area, lined with upscale boutiques, art galleries, and gourmet restaurants. Visit the Aspen Art Museum, explore the historic.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Colorado! The Centennial State is a paradise for outdoor enthusiasts, foodies, and adventure-seekers alike. With its breathtaking Rocky Mountains, charming towns, and vibrant cities, Colorado has something for everyone. Here are the top 3 things to do in Colorado:\\n\\n1. **Explore the Rocky Mountain National Park**: A must-visit destination in Colorado, Rocky Mountain National Park is a stunning showcase of alpine grandeur. With over 60 mountain peaks above 12,000 feet, including Longs Peak, the park offers endless opportunities for hiking, camping, and wildlife viewing. Take a scenic drive on the Trail Ridge Road, the highest paved road in the US, and marvel at the breathtaking vistas. Keep an eye out for elk, moose, and bighorn sheep roaming freely in their natural habitat.\\n\\nSome popular trails in the park include:\\n\\t* Bear Lake Trail: A moderate 3.5-mile loop around Bear Lake, offering stunning views of the surrounding mountains.\\n\\t* Alberta Falls Trail: A 3.8-mile out-and-back trail that takes you to a picturesque waterfall.\\n\\t* Longs Peak Trail: A challenging 14.5-mile out-and-back trail that rewards hikers with panoramic views from the summit.\\n\\n2. **Experience the Thrill of Skiing or Snowboarding in the Rockies**: Colorado is renowned for its world-class ski resorts, and for good reason. With some of the best snow on the planet, resorts like Vail, Aspen, and Breckenridge offer an unforgettable winter sports experience. Whether you're a seasoned pro or a beginner, you'll find a resort that suits your style. Enjoy the thrill of speeding down the slopes, take in the stunning mountain views, and cozy up by the fire with a warm cup of hot chocolate.\\n\\nSome top ski resorts in Colorado include:\\n\\t* Vail: With over 5,200 acres of skiable terrain, Vail is one of the largest ski resorts in the US.\\n\\t* Aspen: A luxurious ski destination with four separate ski areas: Aspen Mountain, Aspen Highlands, Buttermilk, and Snowmass.\\n\\t* Breckenridge: A lively ski resort with a wide range of terrain, from gentle groomers to challenging black diamond runs.\\n\\n3. **Discover the Charm of Downtown Aspen**: Aspen is a picturesque mountain town that's as famous for its natural beauty as it is for its cultural attractions. Stroll through the charming downtown area, lined with upscale boutiques, art galleries, and gourmet restaurants. Visit the Aspen Art Museum, explore the historic\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils.llms\n",
    "reload(utils.llms)\n",
    "\n",
    "from utils.llms import CustomOpenAIClient\n",
    "\n",
    "llm = CustomOpenAIClient(enable_streaming=False)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a travel agent. Be descriptive and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me the top 3 things to do in Colorado.\"},\n",
    "]\n",
    "\n",
    "\n",
    "llm.generate(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca43978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:48:17,539 - DEBUG:openai._base_client:_base_client.py - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\\n\\nIf you don't know the user ID, ask the user to provide it.\"}, {'role': 'user', 'content': 'Can I get a referal code? My user ID is 3431235UK.'}], 'model': 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', 'max_tokens': 512, 'stream': False, 'temperature': 0.8, 'tools': [{'type': 'function', 'function': {'name': 'get_referal_code', 'description': 'Get the referal code for a user', 'parameters': {'type': 'object', 'properties': {'user_id': {'type': 'string', 'description': 'The user ID for which to get the referal code.'}}}}}], 'top_p': 0.9}}\n",
      "2025-05-09 23:48:17,540 - DEBUG:openai._base_client:_base_client.py - Sending HTTP Request: POST https://api.together.xyz/v1/chat/completions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 23:48:18,498 - DEBUG:openai._base_client:_base_client.py - HTTP Response: POST https://api.together.xyz/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 10 May 2025 05:48:18 GMT', 'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93d725921e2de673-DEN', 'cf-cache-status': 'DYNAMIC', 'retry-after': '2', 'access-control-allow-origin': '*', 'etag': 'W/\"319-FdCPPChAeAEplwzP0y1i3ztPE3k\"', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-amzn-trace-id': '338c0936-df59-41f3-90dc-f6e83147861c-noamzn', 'x-api-call-end': '2025-05-10T05:48:18.483Z', 'x-api-call-start': '2025-05-10T05:48:17.777Z', 'x-api-received': '2025-05-10T05:48:17.768Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '10', 'x-ratelimit-limit-tokens': '3000', 'x-ratelimit-remaining': '19', 'x-ratelimit-remaining-tokens': '3000', 'x-ratelimit-reset': '2', 'x-request-id': 'ntSh7KD-zqrih-93d725921e2de673', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-05-09 23:48:18,499 - DEBUG:openai._base_client:_base_client.py - request_id: ntSh7KD-zqrih-93d725921e2de673\n",
      "2025-05-09 23:48:18,500 - DEBUG:utils.llms:llms.py - Generating response; prompt= [{'role': 'system', 'content': \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\\n\\nIf you don't know the user ID, ask the user to provide it.\"}, {'role': 'user', 'content': 'Can I get a referal code? My user ID is 3431235UK.'}]\n",
      "2025-05-09 23:48:18,501 - DEBUG:utils.llms:llms.py - Tools enabled. Returning raw result: ChatCompletion(id='ntSh7KD-zqrih-93d725921e2de673', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_mmpr3bycgzrazr8lfql1s4of', function=Function(arguments='{\"user_id\":\"3431235UK\"}', name='get_referal_code'), type='function', index=0)]), seed=None)], created=1746856097, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=66, prompt_tokens=235, total_tokens=301), prompt=[]).\n",
      "2025-05-09 23:48:18,506 - DEBUG:openai._base_client:_base_client.py - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\\n\\nIf you don't know the user ID, ask the user to provide it.\"}, {'role': 'user', 'content': 'Can I get a referal code? My user ID is 3431235UK.'}, {'tool_call_id': 'call_mmpr3bycgzrazr8lfql1s4of', 'role': 'tool', 'name': 'get_referal_code', 'content': '{\"referral_code\": \"REF-3431235UK\", \"expiration_time\": \"2025-05-11 23:48:18\"}'}], 'model': 'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', 'max_tokens': 512, 'stream': True, 'temperature': 0.8, 'tools': None, 'top_p': 0.9}}\n",
      "2025-05-09 23:48:18,507 - DEBUG:openai._base_client:_base_client.py - Sending HTTP Request: POST https://api.together.xyz/v1/chat/completions\n",
      "2025-05-09 23:48:18,614 - DEBUG:openai._base_client:_base_client.py - HTTP Response: POST https://api.together.xyz/v1/chat/completions \"200 OK\" Headers({'date': 'Sat, 10 May 2025 05:48:18 GMT', 'content-type': 'text/event-stream;charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'cf-ray': '93d72597d9d2e673-DEN', 'cf-cache-status': 'DYNAMIC', 'retry-after': '1', 'access-control-allow-origin': '*', 'cache-control': 'no-cache, no-transform', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-amzn-trace-id': '5c85f828-da87-4673-b220-2211be87114e-noamzn', 'x-api-call-start': '2025-05-10T05:48:18.581Z', 'x-api-received': '2025-05-10T05:48:18.572Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '10', 'x-ratelimit-limit-tokens': '3000', 'x-ratelimit-remaining': '18', 'x-ratelimit-remaining-tokens': '2699', 'x-ratelimit-reset': '1', 'x-request-id': 'ntSh7Z5-zqrih-93d72597d9d2e673', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "2025-05-09 23:48:18,614 - DEBUG:openai._base_client:_base_client.py - request_id: ntSh7Z5-zqrih-93d72597d9d2e673\n",
      "2025-05-09 23:48:18,615 - DEBUG:utils.llms:llms.py - Generating response; prompt= [{'role': 'system', 'content': \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\\n\\nIf you don't know the user ID, ask the user to provide it.\"}, {'role': 'user', 'content': 'Can I get a referal code? My user ID is 3431235UK.'}, {'tool_call_id': 'call_mmpr3bycgzrazr8lfql1s4of', 'role': 'tool', 'name': 'get_referal_code', 'content': '{\"referral_code\": \"REF-3431235UK\", \"expiration_time\": \"2025-05-11 23:48:18\"}'}]\n",
      "2025-05-09 23:48:18,615 - DEBUG:utils.llms:llms.py - Streaming response enabled. Returning generator.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<openai.Stream at 0x165057c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from utils.llms import CustomOpenAIClient\n",
    "from utils.dummy_apis import get_referal_code\n",
    "from utils.agentic_tools import GET_REFERRAL_CODE_TOOL\n",
    "\n",
    "\n",
    "llm = CustomOpenAIClient(enable_streaming=True)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\\n\\nIf you don't know the user ID, ask the user to provide it.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can I get a referal code? My user ID is 3431235UK.\"},\n",
    "]\n",
    "    \n",
    "# Completion #1: Get the appropriate tool calls\n",
    "response = llm.generate(\n",
    "    messages=messages,\n",
    "    tools=GET_REFERRAL_CODE_TOOL,\n",
    ")\n",
    "\n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "if tool_calls:\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        if function_name == \"get_referal_code\":\n",
    "            function_response = get_referal_code(\n",
    "                user_id=function_args.get(\"user_id\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Completion #2: Provide the results to get the final answer\n",
    "function_enriched_response = llm.generate(\n",
    "    messages=messages,\n",
    ")\n",
    "    \n",
    "function_enriched_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7df075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='Your', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='Your')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' referral', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' referral')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' code', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' code')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' is', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' is')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' REF', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' REF')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='-', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='-')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='343', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='343')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='123', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='123')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='5')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='UK', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='UK')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=',')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' and')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' it', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' it')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' will', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' will')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' expire', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' expire')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' on', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' on')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' May', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' May')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' ')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='11', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='11')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=',')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' ')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='202', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='202')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='5')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=',')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' at', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' at')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=' ', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=' ')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='23', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='23')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=':')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='48', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='48')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text=':')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='18', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='18')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason=None, index=0, logprobs=None, text='.')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, role='assistant', tool_calls=None, token_id=None), finish_reason='stop', index=0, logprobs=None, text='')], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=None),\n",
       " ChatCompletionChunk(id='ntSh7Z5-zqrih-93d72597d9d2e673', choices=[], created=1746856098, model='meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8', object='chat.completion.chunk', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=33, prompt_tokens=132, total_tokens=165))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in function_enriched_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f691b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([chunk.choices[0].delta.content for chunk in function_enriched_response if chunk.choices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41fb911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e836d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
